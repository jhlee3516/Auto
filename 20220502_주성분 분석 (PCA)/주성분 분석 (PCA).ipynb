{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주성분 분석(PCA)\n",
    "주성분 분석은 특성들이 통계적으로 상관관계가 없도록 데이터셋을 회전시키는 기술입니다.  \n",
    "PCA를 적용하기 전에 StandardScaler를 사용해 각 특성의 분산이 1이 되도록 데이터의 스케일을 조정합니다.  \n",
    "왜냐하면 특성의 스케일이 다르면 올바른 주성분을 찾을 수 없기 때문입니다.  \n",
    "유튜브: https://youtu.be/JZD_nbg4HBc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(cancer.data)\n",
    "X_scaled = scaler.transform(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 형태:  (569, 30)\n",
      "축소된 데이터 형태:  (569, 2)\n"
     ]
    }
   ],
   "source": [
    "print('원본 데이터 형태: ', str(X_scaled.shape))\n",
    "print('축소된 데이터 형태: ', str(X_pca.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.09706398, -2.07333501,  1.26993369,  0.9843749 ,  1.56846633,\n",
       "        3.28351467,  2.65287398,  2.53247522,  2.21751501,  2.25574689,\n",
       "        2.48973393, -0.56526506,  2.83303087,  2.48757756, -0.21400165,\n",
       "        1.31686157,  0.72402616,  0.66081994,  1.14875667,  0.90708308,\n",
       "        1.88668963, -1.35929347,  2.30360062,  2.00123749,  1.30768627,\n",
       "        2.61666502,  2.10952635,  2.29607613,  2.75062224,  1.93701461])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.19283683, 1.94858307])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "X = df[['매매순서','최대거래대금','직전 거래대금','양봉개수','10이격도','20이격도','60이격도','매수등락률','시가등락률','뉴스기사','분봉전고점']]\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 형태:  (122, 11)\n",
      "축소된 데이터 형태:  (122, 6)\n"
     ]
    }
   ],
   "source": [
    "print('원본 데이터 형태: ', str(X_scaled.shape))\n",
    "print('축소된 데이터 형태: ', str(X_pca.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주문일자</th>\n",
       "      <th>종목명</th>\n",
       "      <th>매수가격</th>\n",
       "      <th>매수시간</th>\n",
       "      <th>매도시간</th>\n",
       "      <th>수익률</th>\n",
       "      <th>매매순서</th>\n",
       "      <th>최대거래대금 시간</th>\n",
       "      <th>최대거래대금</th>\n",
       "      <th>직전 거래대금</th>\n",
       "      <th>양봉개수</th>\n",
       "      <th>10이격도</th>\n",
       "      <th>20이격도</th>\n",
       "      <th>60이격도</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>매수등락률</th>\n",
       "      <th>시가등락률</th>\n",
       "      <th>뉴스기사</th>\n",
       "      <th>분봉전고점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>고려시멘트</td>\n",
       "      <td>5230</td>\n",
       "      <td>09:09:07</td>\n",
       "      <td>09:21:27</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1</td>\n",
       "      <td>09:06:00</td>\n",
       "      <td>113</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4.38</td>\n",
       "      <td>9.72</td>\n",
       "      <td>13.32</td>\n",
       "      <td>198440</td>\n",
       "      <td>16.22</td>\n",
       "      <td>6.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>고려시멘트</td>\n",
       "      <td>5410</td>\n",
       "      <td>09:28:09</td>\n",
       "      <td>09:32:19</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2</td>\n",
       "      <td>09:06:00</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.72</td>\n",
       "      <td>11.55</td>\n",
       "      <td>198440</td>\n",
       "      <td>20.22</td>\n",
       "      <td>6.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>영진약품</td>\n",
       "      <td>5490</td>\n",
       "      <td>09:51:11</td>\n",
       "      <td>09:55:24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3</td>\n",
       "      <td>09:50:00</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.94</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3520</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>버킷스튜디오</td>\n",
       "      <td>5060</td>\n",
       "      <td>09:58:16</td>\n",
       "      <td>09:59:56</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>09:22:00</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.17</td>\n",
       "      <td>66410</td>\n",
       "      <td>11.58</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>우리바이오</td>\n",
       "      <td>4390</td>\n",
       "      <td>10:00:40</td>\n",
       "      <td>10:00:50</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.23</td>\n",
       "      <td>82850</td>\n",
       "      <td>10.86</td>\n",
       "      <td>4.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         주문일자     종목명  매수가격      매수시간      매도시간   수익률  매매순서 최대거래대금 시간  최대거래대금  \\\n",
       "0  2022-03-29   고려시멘트  5230  09:09:07  09:21:27  2.57     1  09:06:00     113   \n",
       "1  2022-03-29   고려시멘트  5410  09:28:09  09:32:19  1.55     2  09:06:00     113   \n",
       "2  2022-03-29    영진약품  5490  09:51:11  09:55:24  0.36     3  09:50:00      62   \n",
       "3  2022-03-29  버킷스튜디오  5060  09:58:16  09:59:56 -0.89     4  09:22:00      72   \n",
       "4  2022-03-29   우리바이오  4390  10:00:40  10:00:50 -0.87     5  10:00:00      44   \n",
       "\n",
       "   직전 거래대금  양봉개수  10이격도  20이격도  60이격도    종목코드  매수등락률  시가등락률  뉴스기사  분봉전고점  \n",
       "0       63     1   4.38   9.72  13.32  198440  16.22   6.22     1   0.38  \n",
       "1       16     2   0.93   1.72  11.55  198440  20.22   6.22     1   1.29  \n",
       "2       62     1   1.57   1.94   4.43    3520   6.60   0.19     1   3.28  \n",
       "3       26     0   0.87   2.06   4.17   66410  11.58   3.09     1   0.99  \n",
       "4       43     3   3.56   4.06   4.23   82850  10.86   4.17     1   1.94  "
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['수익률'] = df['수익률'].apply(lambda x : 1 if x > 0 else 0 )\n",
    "df['수익률'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['매매순서','최대거래대금','직전 거래대금','양봉개수','10이격도','20이격도','60이격도','매수등락률','시가등락률','뉴스기사','분봉전고점']]\n",
    "y = df['수익률']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "optimizer = Adagrad()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.6913 - acc: 0.5246\n",
      "Epoch 2/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6789 - acc: 0.5574\n",
      "Epoch 3/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6750 - acc: 0.5656\n",
      "Epoch 4/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6710 - acc: 0.5574\n",
      "Epoch 5/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6690 - acc: 0.5574\n",
      "Epoch 6/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6672 - acc: 0.5656\n",
      "Epoch 7/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6657 - acc: 0.5656\n",
      "Epoch 8/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6644 - acc: 0.5656\n",
      "Epoch 9/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6635 - acc: 0.5656\n",
      "Epoch 10/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6625 - acc: 0.5656\n",
      "Epoch 11/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6611 - acc: 0.5656\n",
      "Epoch 12/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6606 - acc: 0.5574\n",
      "Epoch 13/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6595 - acc: 0.5656\n",
      "Epoch 14/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6587 - acc: 0.5656\n",
      "Epoch 15/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6581 - acc: 0.5656\n",
      "Epoch 16/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6574 - acc: 0.5738\n",
      "Epoch 17/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6567 - acc: 0.5738\n",
      "Epoch 18/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6560 - acc: 0.5820\n",
      "Epoch 19/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6556 - acc: 0.5820\n",
      "Epoch 20/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6553 - acc: 0.5820\n",
      "Epoch 21/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6545 - acc: 0.5656\n",
      "Epoch 22/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6540 - acc: 0.5738\n",
      "Epoch 23/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6535 - acc: 0.5820\n",
      "Epoch 24/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6530 - acc: 0.5820\n",
      "Epoch 25/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6526 - acc: 0.5820\n",
      "Epoch 26/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6524 - acc: 0.5738\n",
      "Epoch 27/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6519 - acc: 0.5820\n",
      "Epoch 28/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6516 - acc: 0.5820\n",
      "Epoch 29/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6510 - acc: 0.5820\n",
      "Epoch 30/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6507 - acc: 0.5820\n",
      "Epoch 31/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6506 - acc: 0.5738\n",
      "Epoch 32/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6502 - acc: 0.5738\n",
      "Epoch 33/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6499 - acc: 0.5820\n",
      "Epoch 34/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6496 - acc: 0.5820\n",
      "Epoch 35/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6495 - acc: 0.5738\n",
      "Epoch 36/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6492 - acc: 0.5820\n",
      "Epoch 37/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6487 - acc: 0.5820\n",
      "Epoch 38/200\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.6487 - acc: 0.5820\n",
      "Epoch 39/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6482 - acc: 0.5820\n",
      "Epoch 40/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6478 - acc: 0.5820\n",
      "Epoch 41/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6478 - acc: 0.5820\n",
      "Epoch 42/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6472 - acc: 0.5820\n",
      "Epoch 43/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6472 - acc: 0.5820\n",
      "Epoch 44/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6468 - acc: 0.5820\n",
      "Epoch 45/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6470 - acc: 0.5820\n",
      "Epoch 46/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6467 - acc: 0.5820\n",
      "Epoch 47/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6465 - acc: 0.5820\n",
      "Epoch 48/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6461 - acc: 0.5738\n",
      "Epoch 49/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6459 - acc: 0.5738\n",
      "Epoch 50/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6456 - acc: 0.5738\n",
      "Epoch 51/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6453 - acc: 0.5738\n",
      "Epoch 52/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6453 - acc: 0.5820\n",
      "Epoch 53/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6448 - acc: 0.5820\n",
      "Epoch 54/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6447 - acc: 0.5820\n",
      "Epoch 55/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6444 - acc: 0.5820\n",
      "Epoch 56/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.6607 - acc: 0.550 - 0s 107us/step - loss: 0.6444 - acc: 0.5820\n",
      "Epoch 57/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6439 - acc: 0.5820\n",
      "Epoch 58/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6439 - acc: 0.5738\n",
      "Epoch 59/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6437 - acc: 0.5820\n",
      "Epoch 60/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6432 - acc: 0.5820\n",
      "Epoch 61/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6431 - acc: 0.5738\n",
      "Epoch 62/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6429 - acc: 0.5738\n",
      "Epoch 63/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6428 - acc: 0.5738\n",
      "Epoch 64/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6424 - acc: 0.5820\n",
      "Epoch 65/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6424 - acc: 0.5820\n",
      "Epoch 66/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6422 - acc: 0.5820\n",
      "Epoch 67/200\n",
      "122/122 [==============================] - 0s 164us/step - loss: 0.6420 - acc: 0.5820\n",
      "Epoch 68/200\n",
      "122/122 [==============================] - 0s 156us/step - loss: 0.6418 - acc: 0.5820\n",
      "Epoch 69/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6418 - acc: 0.5820\n",
      "Epoch 70/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6414 - acc: 0.5820\n",
      "Epoch 71/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6413 - acc: 0.5820\n",
      "Epoch 72/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6411 - acc: 0.5820\n",
      "Epoch 73/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6410 - acc: 0.5820\n",
      "Epoch 74/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6409 - acc: 0.5820\n",
      "Epoch 75/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6407 - acc: 0.5820\n",
      "Epoch 76/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6404 - acc: 0.5820\n",
      "Epoch 77/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6404 - acc: 0.5820\n",
      "Epoch 78/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6401 - acc: 0.5820\n",
      "Epoch 79/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6400 - acc: 0.5820\n",
      "Epoch 80/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6399 - acc: 0.5820\n",
      "Epoch 81/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6397 - acc: 0.5820\n",
      "Epoch 82/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6395 - acc: 0.5820\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 148us/step - loss: 0.6392 - acc: 0.5820\n",
      "Epoch 84/200\n",
      "122/122 [==============================] - 0s 156us/step - loss: 0.6392 - acc: 0.5902\n",
      "Epoch 85/200\n",
      "122/122 [==============================] - 0s 139us/step - loss: 0.6389 - acc: 0.5902\n",
      "Epoch 86/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6388 - acc: 0.5820\n",
      "Epoch 87/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6387 - acc: 0.5820\n",
      "Epoch 88/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6385 - acc: 0.5820\n",
      "Epoch 89/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6384 - acc: 0.5820\n",
      "Epoch 90/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.5857 - acc: 0.700 - 0s 123us/step - loss: 0.6382 - acc: 0.5820\n",
      "Epoch 91/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6380 - acc: 0.5820\n",
      "Epoch 92/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6378 - acc: 0.5820\n",
      "Epoch 93/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6378 - acc: 0.5820\n",
      "Epoch 94/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6376 - acc: 0.5820\n",
      "Epoch 95/200\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6374 - acc: 0.5820\n",
      "Epoch 96/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6372 - acc: 0.5820\n",
      "Epoch 97/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6372 - acc: 0.5820\n",
      "Epoch 98/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6370 - acc: 0.5902\n",
      "Epoch 99/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6368 - acc: 0.5902\n",
      "Epoch 100/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6367 - acc: 0.5984\n",
      "Epoch 101/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6365 - acc: 0.5902\n",
      "Epoch 102/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6363 - acc: 0.5902\n",
      "Epoch 103/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6363 - acc: 0.5902\n",
      "Epoch 104/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6361 - acc: 0.5902\n",
      "Epoch 105/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6361 - acc: 0.5902\n",
      "Epoch 106/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6359 - acc: 0.5902\n",
      "Epoch 107/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6357 - acc: 0.6066\n",
      "Epoch 108/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6356 - acc: 0.5984\n",
      "Epoch 109/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6354 - acc: 0.6066\n",
      "Epoch 110/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6354 - acc: 0.5984\n",
      "Epoch 111/200\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6352 - acc: 0.5984\n",
      "Epoch 112/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6351 - acc: 0.6066\n",
      "Epoch 113/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6349 - acc: 0.6066\n",
      "Epoch 114/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6348 - acc: 0.5984\n",
      "Epoch 115/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6347 - acc: 0.5984\n",
      "Epoch 116/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6345 - acc: 0.5984\n",
      "Epoch 117/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6341 - acc: 0.6066\n",
      "Epoch 118/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6342 - acc: 0.6066\n",
      "Epoch 119/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6340 - acc: 0.6066\n",
      "Epoch 120/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6341 - acc: 0.6066\n",
      "Epoch 121/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6338 - acc: 0.6066\n",
      "Epoch 122/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6337 - acc: 0.6148\n",
      "Epoch 123/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6335 - acc: 0.6148\n",
      "Epoch 124/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6333 - acc: 0.6148\n",
      "Epoch 125/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6332 - acc: 0.6148\n",
      "Epoch 126/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6330 - acc: 0.6393\n",
      "Epoch 127/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6328 - acc: 0.6557\n",
      "Epoch 128/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6327 - acc: 0.6311\n",
      "Epoch 129/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6325 - acc: 0.6393\n",
      "Epoch 130/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6323 - acc: 0.6557\n",
      "Epoch 131/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6322 - acc: 0.6557\n",
      "Epoch 132/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6320 - acc: 0.6557\n",
      "Epoch 133/200\n",
      "122/122 [==============================] - 0s 148us/step - loss: 0.6319 - acc: 0.6639\n",
      "Epoch 134/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6318 - acc: 0.6557\n",
      "Epoch 135/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6316 - acc: 0.6639\n",
      "Epoch 136/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6317 - acc: 0.6557\n",
      "Epoch 137/200\n",
      "122/122 [==============================] - 0s 139us/step - loss: 0.6316 - acc: 0.6557\n",
      "Epoch 138/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6314 - acc: 0.6557\n",
      "Epoch 139/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6313 - acc: 0.6557\n",
      "Epoch 140/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6312 - acc: 0.6557\n",
      "Epoch 141/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6310 - acc: 0.6639\n",
      "Epoch 142/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6309 - acc: 0.6639\n",
      "Epoch 143/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6306 - acc: 0.6639\n",
      "Epoch 144/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6305 - acc: 0.6557\n",
      "Epoch 145/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6304 - acc: 0.6557\n",
      "Epoch 146/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6303 - acc: 0.6557\n",
      "Epoch 147/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6301 - acc: 0.6639\n",
      "Epoch 148/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6299 - acc: 0.6639\n",
      "Epoch 149/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6299 - acc: 0.6557\n",
      "Epoch 150/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6297 - acc: 0.6557\n",
      "Epoch 151/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6296 - acc: 0.6557\n",
      "Epoch 152/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6294 - acc: 0.6557\n",
      "Epoch 153/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6294 - acc: 0.6557\n",
      "Epoch 154/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6293 - acc: 0.6557\n",
      "Epoch 155/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6292 - acc: 0.6557\n",
      "Epoch 156/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6290 - acc: 0.6557\n",
      "Epoch 157/200\n",
      "122/122 [==============================] - 0s 139us/step - loss: 0.6289 - acc: 0.6557\n",
      "Epoch 158/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6287 - acc: 0.6639\n",
      "Epoch 159/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6286 - acc: 0.6639\n",
      "Epoch 160/200\n",
      "122/122 [==============================] - 0s 131us/step - loss: 0.6285 - acc: 0.6557\n",
      "Epoch 161/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6282 - acc: 0.6803\n",
      "Epoch 162/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6281 - acc: 0.6639\n",
      "Epoch 163/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6279 - acc: 0.6639\n",
      "Epoch 164/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6279 - acc: 0.6721\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 115us/step - loss: 0.6277 - acc: 0.6885\n",
      "Epoch 166/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6277 - acc: 0.6885\n",
      "Epoch 167/200\n",
      "122/122 [==============================] - 0s 139us/step - loss: 0.6275 - acc: 0.6885\n",
      "Epoch 168/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6274 - acc: 0.6885\n",
      "Epoch 169/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6273 - acc: 0.6885\n",
      "Epoch 170/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6270 - acc: 0.6885\n",
      "Epoch 171/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6268 - acc: 0.6885\n",
      "Epoch 172/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6267 - acc: 0.6967\n",
      "Epoch 173/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6267 - acc: 0.6967\n",
      "Epoch 174/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6267 - acc: 0.6967\n",
      "Epoch 175/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.6114 - acc: 0.650 - 0s 107us/step - loss: 0.6265 - acc: 0.6967\n",
      "Epoch 176/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6262 - acc: 0.6967\n",
      "Epoch 177/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6261 - acc: 0.6967\n",
      "Epoch 178/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6259 - acc: 0.6967\n",
      "Epoch 179/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6258 - acc: 0.6967\n",
      "Epoch 180/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6256 - acc: 0.6967\n",
      "Epoch 181/200\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6256 - acc: 0.6967\n",
      "Epoch 182/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6255 - acc: 0.6885\n",
      "Epoch 183/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6252 - acc: 0.6967\n",
      "Epoch 184/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6250 - acc: 0.6967\n",
      "Epoch 185/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6250 - acc: 0.6967\n",
      "Epoch 186/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6248 - acc: 0.6885\n",
      "Epoch 187/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6246 - acc: 0.6885\n",
      "Epoch 188/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6246 - acc: 0.6803\n",
      "Epoch 189/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6244 - acc: 0.6885\n",
      "Epoch 190/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6243 - acc: 0.6885\n",
      "Epoch 191/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6241 - acc: 0.6885\n",
      "Epoch 192/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6242 - acc: 0.6967\n",
      "Epoch 193/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6239 - acc: 0.6967\n",
      "Epoch 194/200\n",
      "122/122 [==============================] - 0s 107us/step - loss: 0.6239 - acc: 0.6967\n",
      "Epoch 195/200\n",
      "122/122 [==============================] - 0s 123us/step - loss: 0.6236 - acc: 0.6967\n",
      "Epoch 196/200\n",
      "122/122 [==============================] - 0s 115us/step - loss: 0.6236 - acc: 0.6967\n",
      "Epoch 197/200\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6235 - acc: 0.6967\n",
      "Epoch 198/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6233 - acc: 0.6967\n",
      "Epoch 199/200\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6234 - acc: 0.6967\n",
      "Epoch 200/200\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6232 - acc: 0.6967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1737477ef98>"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 20ms/step\n",
      "0.7560975667906971\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  3],\n",
       "       [ 7,  7]], dtype=int64)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, np.rint(y_pred))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "주성분 분석을 활용하니 score가 대폭 개선되었다. 이전에는 0.6이 한계였는데 이제는 0.7도 가능하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
